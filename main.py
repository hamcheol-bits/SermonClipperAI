import os
import datetime
from src.transcriber import transcribe_video
from src.audio_analyzer import analyze_audio_structure, find_sermon_candidates_by_audio  # <-- ì‹ ê·œ ë¡œì§
from src.decision_maker import classify_sequence
from src.editor import cut_video, extract_audio
from src.config import INPUT_DIR, OUTPUT_DIR


def seconds_to_hms(seconds):
    return str(datetime.timedelta(seconds=int(seconds)))


def find_exact_boundary(segments, rough_time, direction='start'):
    """
    ì˜¤ë””ì˜¤ ë¶„ì„ìœ¼ë¡œ ì°¾ì€ rough_time ê·¼ì²˜(ì•ë’¤ 60ì´ˆ)ë§Œ Llama3ë¡œ ì •ë°€ ê²€ì‚¬
    direction: 'start'ë©´ ì„¤êµ ì‹œì‘ì , 'end'ë©´ ì„¤êµ ëì  ì°¾ê¸°
    """
    # rough_timeì— ê°€ì¥ ê°€ê¹Œìš´ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ ì°¾ê¸°
    if not segments:
        return rough_time

    center_idx = min(range(len(segments)), key=lambda i: abs(segments[i]['start'] - rough_time))

    # íƒìƒ‰ ë²”ìœ„: Whisper ì„¸ê·¸ë¨¼íŠ¸ ê¸°ì¤€ ì•ë’¤ 15ê°œ (ì•½ 1ë¶„~1ë¶„30ì´ˆ ë²”ìœ„)
    search_radius = 15
    start_idx = max(0, center_idx - search_radius)
    end_idx = min(len(segments), center_idx + search_radius)

    scan_type = "ì‹œì‘ì " if direction == 'start' else "ì¢…ë£Œì "
    print(f"ğŸ” [Fine-Tuning] {scan_type} ì •ë°€ íƒìƒ‰ ({seconds_to_hms(rough_time)} ê·¼ì²˜)...")

    # 1. ì‹œì‘ì  ì°¾ê¸°: "ì°¬ì–‘/ê¸°íƒ€" -> "ì„¤êµ"ë¡œ ë°”ë€ŒëŠ” ìˆœê°„
    if direction == 'start':
        for i in range(start_idx, end_idx):
            # ë¬¸ë§¥ íŒŒì•…ì„ ìœ„í•´ 3ë¬¸ì¥ í•©ì¹¨
            buffer = " ".join([s['text'] for s in segments[i:i + 3] if i + 3 < len(segments)])
            category = classify_sequence(buffer)

            # ë””ë²„ê¹…ìš© ë¡œê·¸ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
            # print(f"   Testing [{seconds_to_hms(segments[i]['start'])}] : {category}")

            if category == "SERMON":
                # ì—°ì† 2ë²ˆ ì´ìƒ SERMONì´ë©´ í™•ì • (ì˜¤íƒ ë°©ì§€)
                next_buffer = " ".join([s['text'] for s in segments[i + 1:i + 4] if i + 4 < len(segments)])
                if classify_sequence(next_buffer) == "SERMON":
                    print(f"   âœ… ì„¤êµ ì‹œì‘ í™•ì •: {seconds_to_hms(segments[i]['start'])}")
                    return segments[i]['start']

        # ëª» ì°¾ìœ¼ë©´ ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
        print("   âš ï¸ ì •ë°€ íƒìƒ‰ ì‹¤íŒ¨, ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œê°„ ì‚¬ìš©")
        return rough_time

    # 2. ëì  ì°¾ê¸°: "ì„¤êµ" -> "ê¸°ë„/ì°¬ì–‘"ìœ¼ë¡œ ë°”ë€ŒëŠ” ìˆœê°„
    elif direction == 'end':
        # ë’¤ì—ì„œë¶€í„° ì•ìœ¼ë¡œ ì˜¤ë©´ì„œ SERMONì´ ëë‚˜ëŠ” ê³³ ì°¾ê¸°
        for i in range(end_idx, start_idx, -1):
            if i >= len(segments): continue

            # ì´ì „ 3ë¬¸ì¥ì„ ê²€ì‚¬
            buffer_prev = " ".join([s['text'] for s in segments[i - 3:i] if i - 3 >= 0])
            category_prev = classify_sequence(buffer_prev)

            if category_prev == "SERMON":
                # í˜„ì¬ ì§€ì  ë°”ë¡œ ì•ì´ ì„¤êµì˜€ë‹¤ë©´, ì—¬ê¸°ê°€ ëì 
                cut_point = segments[i]['start']
                print(f"   âœ… ì„¤êµ ì¢…ë£Œ í™•ì •: {seconds_to_hms(cut_point)}")
                return cut_point

        print("   âš ï¸ ì •ë°€ íƒìƒ‰ ì‹¤íŒ¨, ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œê°„ ì‚¬ìš©")
        return rough_time


def main():
    video_file = "ì„±ê°€êµíšŒ 2026ë…„ 1ì›” 14ì¼ ìˆ˜ìš”ì˜ˆë°°.mp4"  # ì²˜ë¦¬í•  íŒŒì¼ëª… (í•„ìš”ì‹œ ë³€ê²½)
    input_path = os.path.join(INPUT_DIR, video_file)

    if not os.path.exists(input_path):
        print(f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        return

    print("ğŸš€ SermonClipperAI ì‹œì‘ (Audio Analysis + AI Mode)")

    # -----------------------------------------
    # 1. ì˜¤ë””ì˜¤ ì¶”ì¶œ ë° êµ¬ì¡° ë¶„ì„ (ê°€ì¥ ì¤‘ìš”)
    # -----------------------------------------
    audio_path = extract_audio(input_path, INPUT_DIR)
    if not audio_path: return

    # ìŒì•…(Music) vs ë§ì†Œë¦¬(Speech) ë¶„ì„
    df_audio = analyze_audio_structure(audio_path)

    # ëŒ€ëµì ì¸ ì„¤êµ êµ¬ê°„(ê°€ì¥ ê¸´ ë§ì†Œë¦¬) ì¶”ì¶œ
    rough_start, rough_end = find_sermon_candidates_by_audio(df_audio)

    if rough_start is None:
        print("âŒ ì„¤êµ êµ¬ê°„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nğŸ“ [1ì°¨ í•„í„°] ì˜¤ë””ì˜¤ ê¸°ë°˜ êµ¬ê°„: {seconds_to_hms(rough_start)} ~ {seconds_to_hms(rough_end)}")

    # -----------------------------------------
    # 2. Whisper STT (ì „ì²´ í…ìŠ¤íŠ¸ í™•ë³´)
    # -----------------------------------------
    # M1 Macì—ì„œëŠ” Whisper ì†ë„ê°€ ë¹ ë¥´ë¯€ë¡œ ì „ì²´ ë³€í™˜ í›„ ë§¤ì¹­í•˜ëŠ” ê²ƒì´ ì •í™•ë„ ë©´ì—ì„œ ìœ ë¦¬í•©ë‹ˆë‹¤.
    segments = transcribe_video(input_path)

    # -----------------------------------------
    # 3. Llama3 ì •ë°€ ë³´ì • (Fine-Tuning)
    # -----------------------------------------
    # ì˜¤ë””ì˜¤ë¡œ ì°¾ì€ ì‹œê°„ ì•ë’¤ë¥¼ LLMì´ í…ìŠ¤íŠ¸ë¡œ ì½ì–´ë³´ë©° 1~2ì´ˆ ë‹¨ìœ„ ë¯¸ì„¸ ì¡°ì •
    final_start = find_exact_boundary(segments, rough_start, direction='start')
    final_end = find_exact_boundary(segments, rough_end, direction='end')

    print(f"\nğŸ¯ [ìµœì¢… ê²°ê³¼] í™•ì • êµ¬ê°„: {seconds_to_hms(final_start)} ~ {seconds_to_hms(final_end)}\n")

    # -----------------------------------------
    # 4. ì˜ìƒ ìë¥´ê¸°
    # -----------------------------------------
    cut_video(input_path, OUTPUT_DIR, final_start, final_end)


if __name__ == "__main__":
    main()